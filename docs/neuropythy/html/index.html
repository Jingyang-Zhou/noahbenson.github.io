
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Welcome to Neuropythy’s documentation! &#8212; Neuropythy 0.3.5 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head>
  <body>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="welcome-to-neuropythy-s-documentation">
<h1>Welcome to Neuropythy’s documentation!<a class="headerlink" href="#welcome-to-neuropythy-s-documentation" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<span class="target" id="module-neuropythy"></span><p>Tools for analyzing and registering cortical meshes.</p>
<dl class="function">
<dt id="neuropythy.load">
<code class="descclassname">neuropythy.</code><code class="descname">load</code><span class="sig-paren">(</span><em>filename</em>, <em>format=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.load" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>load(filename) yields the data contained in the file referenced by the given filename in a</dt>
<dd>neuropythy or neuropythy-friendly format.</dd>
<dt>load(filename, format) specifies that the given format should be used; this should be the name</dt>
<dd>of the importer (though a file extension that is recognized also will work).</dd>
</dl>
<p>Additionally, functions located in load.&lt;format&gt; may be used; so, for example, the following
are equivalent calls:</p>
<blockquote>
<div>load(filename, ‘nifti’)
load.nifti(filename)</div></blockquote>
<p>In fact, the load.nifti function is just the nifti importer, so help(load.nifti) will also
yield documentation for the nifti importer.</p>
<p>Keyword options may be passed to load; these must match those accepted by the given import
function.</p>
</dd></dl>

<dl class="function">
<dt id="neuropythy.save">
<code class="descclassname">neuropythy.</code><code class="descname">save</code><span class="sig-paren">(</span><em>filename</em>, <em>data</em>, <em>format=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.save" title="Permalink to this definition">¶</a></dt>
<dd><p>save(filename, data) writes the given data to the given filename then yieds that filename.
save(filename, data, format) specifies that the given format should be used; this should be the</p>
<blockquote>
<div>name of the exporter (though a file extension that is recognized also will work).</div></blockquote>
<p>Additionally, functions located in save.&lt;format&gt; may be used; so, for example, the following
are equivalent calls:</p>
<blockquote>
<div>save(filename, image, ‘nifti’)
save.nifti(filename, image)</div></blockquote>
<p>In fact, the save.nifti function is just the nifti exporter, so help(save.nifti) will also
yield documentation for the nifti exporter.</p>
<p>Keyword options may be passed to save; these must match those accepted by the given export
function.</p>
</dd></dl>

<dl class="function">
<dt id="neuropythy.to_nifti">
<code class="descclassname">neuropythy.</code><code class="descname">to_nifti</code><span class="sig-paren">(</span><em>obj</em>, <em>like=None</em>, <em>header=None</em>, <em>affine=None</em>, <em>extensions=Ellipsis</em>, <em>version=1</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.to_nifti" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>to_nifti(obj) yields a Nifti2Image object that is as equivalent as possible to the given object</dt>
<dd>obj. If obj is a Nifti2Image already, then it is returned unmolested; other deduction rules
are described below.</dd>
<dt>The following options are accepted:</dt>
<dd><ul class="first last simple">
<li>like (default: None) may be provided to give a guide for the various header- and meta-data
that is included in the image. If this is a nifti image object, its meta-data are used; if
this is a subject, then the meta-data are deduced from the subject’s voxel and native
orientation matrices. All other specific options below override anything deduced from the
like argument.</li>
<li>header (default: None) may be a Nifti1 or Niti2 image header to be used as the nifti header
or to replace the header in a new image.</li>
<li>affine (default: None) may specify the affine transform to be given to the image object.</li>
<li>extensions (default: Ellipsis) may specify a nifti extensions object that should be included
in the header. The default value, Ellipsis, indicates that the extensions should not be
changed, and that None should be used if extensions are not implied in obj (if, for example,
obj is a data array rather than an image object with a header already.</li>
<li>version (default: 2) may be specified as 1 or 2 for a Nifti1Image or Nifti2Image object,
respectively.</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="neuropythy.Cortex">
<em class="property">class </em><code class="descclassname">neuropythy.</code><code class="descname">Cortex</code><span class="sig-paren">(</span><em>imm</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex" title="Permalink to this definition">¶</a></dt>
<dd><p>Cortex is a class that handles a single cortical hemisphere; cortex tracks both the spherical
registrations that can be used for cross-subject interpolation as well as the various surfaces
and cortical layers that can be produced from the combined white/pial surfaces.
Cortex is the go-to class for performing interpolation between subjects as it is a Topology
object and thus knows how to search for common registrations for interpolation and comparison.
Cortex also holds the required methods for creating map projections from spherical
registrations.</p>
<p>Cortex(chirality, tess, surfaces, registrations) is typically used to initialize a cortex
object. The chirality should be either ‘lh’ or ‘rh’; tess must be the tesselation of the cortex
object. The surfaces and registrations arguments should both be (possibly lazy) maps whose
values are the appropriate mesh objects. The surfaces must include ‘white’ and ‘pial’. If the
registrations includes the key ‘native’ this is taken to be the default registration for the
particular cortex object.</p>
<dl class="staticmethod">
<dt id="neuropythy.Cortex.chirality">
<em class="property">static </em><code class="descname">chirality</code><span class="sig-paren">(</span><em>ch</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.chirality" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.chirality gives the chirality (‘lh’ or ‘rh’) for the given cortex.</p>
</dd></dl>

<dl class="method">
<dt id="neuropythy.Cortex.from_image">
<code class="descname">from_image</code><span class="sig-paren">(</span><em>image</em>, <em>surface='midgray'</em>, <em>affine=None</em>, <em>method=None</em>, <em>fill=0</em>, <em>dtype=None</em>, <em>native_to_vertex_matrix=None</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.from_image" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.from_image(image) is equivalent to cortex.midgray_surface.from_image(image).
cortex.from_image(image, surface) uses the given surface (see also cortex.surface).</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.midgray_surface">
<em class="property">static </em><code class="descname">midgray_surface</code><span class="sig-paren">(</span><em>white_surface</em>, <em>pial_surface</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.midgray_surface" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.midgray_surface is the mesh representing the midgray surface half way between the
white and pial surfaces.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.pial_surface">
<em class="property">static </em><code class="descname">pial_surface</code><span class="sig-paren">(</span><em>surfaces</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.pial_surface" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.pial_surface is the mesh representing the pial surface of the given cortex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.repr">
<em class="property">static </em><code class="descname">repr</code><span class="sig-paren">(</span><em>chirality</em>, <em>tess</em>, <em>vertex_count</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.repr" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.repr is equivalent to repr(cortex).</p>
</dd></dl>

<dl class="method">
<dt id="neuropythy.Cortex.surface">
<code class="descname">surface</code><span class="sig-paren">(</span><em>name='white'</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.surface" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.surface() yields the white surface of the given cortex
cortex.surface(name) yields the surface with the given name (e.g., ‘white’, ‘pial’,</p>
<blockquote>
<div>‘inflated’, ‘midgray’).</div></blockquote>
<dl class="docutils">
<dt>cortex.surface(fraction) yields the surface that is &lt;fraction&gt; of the distance from white</dt>
<dd>to pial (0 is equivalent to ‘white’; 1 is equivalent to ‘pial’). Layers outside of the
range 0-1 may be returned by following the vectors between white and pial surfaces, but
they may have odd appearances, and this should not be confused with surface inflation.</dd>
</dl>
<p>cortex.surface([dist]) yields the layer that is the given distance from the white surface.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.surface_coordinates">
<em class="property">static </em><code class="descname">surface_coordinates</code><span class="sig-paren">(</span><em>surfs</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.surface_coordinates" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.surface_coordinates is a mapping of the surface coordinates of the given cortex; this
must include the surfaces ‘white’ and ‘pial’.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.surfaces">
<em class="property">static </em><code class="descname">surfaces</code><span class="sig-paren">(</span><em>surface_coordinates</em>, <em>properties</em>, <em>tess</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.surfaces" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.surfaces is a mapping of the surfaces of the given cortex; this must include the
surfaces ‘white’ and ‘pial’.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.validate_surfaces">
<em class="property">static </em><code class="descname">validate_surfaces</code><span class="sig-paren">(</span><em>surfaces</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.validate_surfaces" title="Permalink to this definition">¶</a></dt>
<dd><p>validate_surfaces requires that the surfaces map contain the keys ‘white’ and ‘pial’.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.white_surface">
<em class="property">static </em><code class="descname">white_surface</code><span class="sig-paren">(</span><em>surfaces</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.white_surface" title="Permalink to this definition">¶</a></dt>
<dd><p>cortex.white_surface is the mesh representing the white-matter surface of the given cortex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Cortex.white_to_pial_vectors">
<em class="property">static </em><code class="descname">white_to_pial_vectors</code><span class="sig-paren">(</span><em>white_surface</em>, <em>pial_surface</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Cortex.white_to_pial_vectors" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>cortex.white_to_pial_vectors is a (3 x n) matrix of the unit direction vectors that point</dt>
<dd>from the n vertices in the cortex’s white surface to their equivalent positions in the
pial surface.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuropythy.Subject">
<em class="property">class </em><code class="descclassname">neuropythy.</code><code class="descname">Subject</code><span class="sig-paren">(</span><em>imm</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject" title="Permalink to this definition">¶</a></dt>
<dd><p>Subject is a class that tracks information about an individual subject. A Subject object keeps
track of hemispheres (Cortex objects) as well as some information about the voxels (e.g., the
gray_mask).</p>
<p>When declaring a subject, the hemispheres argument (hemis) should always include at least the
keys ‘lh’ and ‘rh’.
Images should, at a minimum, include the following in their images dictionary:</p>
<blockquote>
<div><ul class="simple">
<li>lh_gray_mask</li>
<li>rh_gray_mask</li>
<li>lh_white_mask</li>
<li>rh_white_mask</li>
</ul>
</div></blockquote>
<p>Alternately, the values with the same names may be overloaded in a daughter class.</p>
<p>Subject respects laziness in the hemis and images classes, and this mechanism is recommended
as a way to lazily load subject data (see pimms.lazy_map).</p>
<dl class="staticmethod">
<dt id="neuropythy.Subject.LH">
<em class="property">static </em><code class="descname">LH</code><span class="sig-paren">(</span><em>hemis</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.LH" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.LH is an alias for sub.hemis[‘lh’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.RH">
<em class="property">static </em><code class="descname">RH</code><span class="sig-paren">(</span><em>hemis</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.RH" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.RH is an alias for sub.hemis[‘rh’].</p>
</dd></dl>

<dl class="method">
<dt id="neuropythy.Subject.cortex_to_image">
<code class="descname">cortex_to_image</code><span class="sig-paren">(</span><em>data</em>, <em>hemi=None</em>, <em>method='linear'</em>, <em>fill=0</em>, <em>dtype=None</em>, <em>affine=None</em>, <em>shape=None</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.cortex_to_image" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.cortex_to_image(data, hemi) projects the given cortical-surface data to the given</dt>
<dd>subject’s gray-matter voxels of the given hemisphere and returns the resulting numpy
array.</dd>
</dl>
<p>sub.cortex_to_image((lh_data, rh_data)) projects into both hemispheres.</p>
<dl class="docutils">
<dt>The following options may be given:</dt>
<dd><ul class="first last simple">
<li>method (default: ‘linear’) specifies that a particular method should be used; valid
options are ‘linear’, ‘heaviest’, and ‘nearest’. The ‘linear’ method uses the
lh_vertex_to_voxel_linear_interpolation and rh_vertex_to_voxel_linear_interpolation 
matrices while ‘nearest’ uses the nearest-neighbor interpolation. The ‘heaviest’ method
uses the highest-valued weight in the ‘linear’ interpolation matrix, which is
equivalent to using nearest-neighbor interpolation after controlling for the depth of
the voxel with respect to the vertices. The ‘linear’ method is generally preferred
unless your data is discreet, in which the ‘heaviest’ method is generally best.</li>
<li>fill (default: 0) specifies the value to be assigned to all voxels not in the gray mask
or voxels in the gray-mask that are missed by the interpolation method.</li>
<li>dtype (default: None) specifies the data type that should be exported. If None, this
will be automatically set to np.float32 for floating-point data and np.int32 for integer
data.</li>
<li>affine (default: None) specifies the affine transformation that should be used to align
the cortical surfaces with the voxels. If None, then the subject’s vertex-to-voxel
matrix will be used.</li>
<li>shape (default: None) specifies the dimensions of the output array; if None, then the
subject’s image_dimensions is used.</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.gray_indices">
<em class="property">static </em><code class="descname">gray_indices</code><span class="sig-paren">(</span><em>lh_gray_indices</em>, <em>rh_gray_indices</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.gray_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.gray_indices is equivalent to numpy.where(sub.gray_mask).</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.hemis">
<em class="property">static </em><code class="descname">hemis</code><span class="sig-paren">(</span><em>h</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.hemis" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.hemis is a persistent map of hemisphere names (‘lh’, ‘rh’, possibly others) for the
given subject sub.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.image_dimensions">
<em class="property">static </em><code class="descname">image_dimensions</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.image_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.image_dimensions is a tuple of the size of an anatomical image for the given subject.</p>
</dd></dl>

<dl class="method">
<dt id="neuropythy.Subject.image_to_cortex">
<code class="descname">image_to_cortex</code><span class="sig-paren">(</span><em>image</em>, <em>surface='midgray'</em>, <em>hemi=None</em>, <em>affine=None</em>, <em>method=None</em>, <em>fill=0</em>, <em>dtype=None</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.image_to_cortex" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.image_to_cortex(image) is equivalent to the tuple</dt>
<dd>(sub.lh.from_image(image), sub.rh.from_image(image)).</dd>
</dl>
<p>sub.image_to_cortex(image, surface) uses the given surface (see also cortex.surface).</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.images">
<em class="property">static </em><code class="descname">images</code><span class="sig-paren">(</span><em>imgs</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.images" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.images is a persistent map of MRImages tracked by the given subject sub.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh">
<em class="property">static </em><code class="descname">lh</code><span class="sig-paren">(</span><em>hemis</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.lh is an alias for sub.hemis[‘lh’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_gray_indices">
<em class="property">static </em><code class="descname">lh_gray_indices</code><span class="sig-paren">(</span><em>lh_gray_mask</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_gray_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.lh_gray_indices is equivalent to numpy.where(sub.lh_gray_mask).</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_gray_mask">
<em class="property">static </em><code class="descname">lh_gray_mask</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_gray_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.lh_gray_mask is an alias for sub.images[‘lh_gray_mask’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_vertex_to_voxel_heaviest_interpolation">
<em class="property">static </em><code class="descname">lh_vertex_to_voxel_heaviest_interpolation</code><span class="sig-paren">(</span><em>lh_vertex_to_voxel_linear_interpolation</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_vertex_to_voxel_heaviest_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.lh_gray_vertex_to_voxel_heaviest_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.lh_gray_indices.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel; the column in each row of the interpolation matrix with the highest
weight is then given a value of 1 while all other rows are given values of 0. This is
equivalent to performing nearest-neighbor interpolation while controlling for the depth of
the voxel in the cortex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_vertex_to_voxel_linear_interpolation">
<em class="property">static </em><code class="descname">lh_vertex_to_voxel_linear_interpolation</code><span class="sig-paren">(</span><em>lh_gray_indices</em>, <em>lh</em>, <em>image_dimensions</em>, <em>voxel_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_vertex_to_voxel_linear_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.lh_gray_vertex_to_voxel_linear_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.lh_gray_indices.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_vertex_to_voxel_lines_interpolation">
<em class="property">static </em><code class="descname">lh_vertex_to_voxel_lines_interpolation</code><span class="sig-paren">(</span><em>lh_gray_indices</em>, <em>lh</em>, <em>image_dimensions</em>, <em>vertex_to_voxel_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_vertex_to_voxel_lines_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.lh_gray_vertex_to_voxel_lines_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.lh_gray_indices.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_vertex_to_voxel_nearest_interpolation">
<em class="property">static </em><code class="descname">lh_vertex_to_voxel_nearest_interpolation</code><span class="sig-paren">(</span><em>lh_gray_indices</em>, <em>lh</em>, <em>voxel_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_vertex_to_voxel_nearest_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.lh_gray_vertex_to_voxel_nearest_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.lh_gray_indices.</dd>
</dl>
<p>The method used is nearest-neighbors to either the closest pial or white surface vertex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_white_indices">
<em class="property">static </em><code class="descname">lh_white_indices</code><span class="sig-paren">(</span><em>lh_white_mask</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_white_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.lh_white_indices is a frozenset of the indices of the white voxels in the given
subject’s lh, represented as 3-tuples.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.lh_white_mask">
<em class="property">static </em><code class="descname">lh_white_mask</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.lh_white_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.lh_white_mask is an alias for sub.images[‘lh_white_mask’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.name">
<em class="property">static </em><code class="descname">name</code><span class="sig-paren">(</span><em>nm</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.name" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.name is the name of the subject sub.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.native_to_vertex_matrix">
<em class="property">static </em><code class="descname">native_to_vertex_matrix</code><span class="sig-paren">(</span><em>native_to_voxel_matrix</em>, <em>voxel_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.native_to_vertex_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.native_to_vertex_matrix is the affine transformation matrix that converts from the
subject’s ‘native’ orientation to the vertex orientation.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.native_to_voxel_matrix">
<em class="property">static </em><code class="descname">native_to_voxel_matrix</code><span class="sig-paren">(</span><em>voxel_to_native_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.native_to_voxel_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.native_to_voxel_matrix is the inverse matrix of sub.voxel_to_native_matrix.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.path">
<em class="property">static </em><code class="descname">path</code><span class="sig-paren">(</span><em>p</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.path" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.path is the path of the subject’s data directory, if any.</p>
</dd></dl>

<dl class="method">
<dt id="neuropythy.Subject.path_join">
<code class="descname">path_join</code><span class="sig-paren">(</span><em>*args</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.path_join" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.path_join(args…) is equivalent to os.path.join(sub.path, args…).</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.repr">
<em class="property">static </em><code class="descname">repr</code><span class="sig-paren">(</span><em>name</em>, <em>path</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.repr" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.repr is the representation string returned by sub.__repr__().</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh">
<em class="property">static </em><code class="descname">rh</code><span class="sig-paren">(</span><em>hemis</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.rh is an alias for sub.hemis[‘rh’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_gray_indices">
<em class="property">static </em><code class="descname">rh_gray_indices</code><span class="sig-paren">(</span><em>rh_gray_mask</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_gray_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.rh_gray_indices is equivalent to numpy.where(sub.rh_gray_mask).</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_gray_mask">
<em class="property">static </em><code class="descname">rh_gray_mask</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_gray_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.rh_gray_mask is an alias for sub.images[‘rh_gray_mask’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_vertex_to_voxel_heaviest_interpolation">
<em class="property">static </em><code class="descname">rh_vertex_to_voxel_heaviest_interpolation</code><span class="sig-paren">(</span><em>rh_vertex_to_voxel_linear_interpolation</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_vertex_to_voxel_heaviest_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_heaviest_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.rh_gray_indices.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel; the column in each row of the interpolation matrix with the highest
weight is then given a value of 1 while all other rows are given values of 0. This is
equivalent to performing nearest-neighbor interpolation while controlling for the depth of
the voxel in the cortex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_vertex_to_voxel_linear_interpolation">
<em class="property">static </em><code class="descname">rh_vertex_to_voxel_linear_interpolation</code><span class="sig-paren">(</span><em>rh_gray_indices</em>, <em>rh</em>, <em>image_dimensions</em>, <em>voxel_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_vertex_to_voxel_linear_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_linear_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.rh_gray_indices.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_vertex_to_voxel_lines_interpolation">
<em class="property">static </em><code class="descname">rh_vertex_to_voxel_lines_interpolation</code><span class="sig-paren">(</span><em>rh_gray_indices</em>, <em>rh</em>, <em>image_dimensions</em>, <em>vertex_to_voxel_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_vertex_to_voxel_lines_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_lines_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.rh_gray_indices.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_vertex_to_voxel_nearest_interpolation">
<em class="property">static </em><code class="descname">rh_vertex_to_voxel_nearest_interpolation</code><span class="sig-paren">(</span><em>rh_gray_indices</em>, <em>rh</em>, <em>voxel_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_vertex_to_voxel_nearest_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_nearest_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.lh_gray_indices.</dd>
</dl>
<p>The method used is nearest-neighbors to either the closest pial or white surface vertex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_white_indices">
<em class="property">static </em><code class="descname">rh_white_indices</code><span class="sig-paren">(</span><em>rh_white_mask</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_white_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.rh_white_indices is a frozenset of the indices of the white voxels in the given
subject’s rh, represented as 3-tuples.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.rh_white_mask">
<em class="property">static </em><code class="descname">rh_white_mask</code><span class="sig-paren">(</span><em>images</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.rh_white_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.rh_white_mask is an alias for sub.images[‘rh_white_mask’].</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.vertex_to_native_matrix">
<em class="property">static </em><code class="descname">vertex_to_native_matrix</code><span class="sig-paren">(</span><em>native_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.vertex_to_native_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.vertex_to_native_matrix is the inverse matrix of sub.native_to_vertex_matrix.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.vertex_to_voxel_linear_interpolation">
<em class="property">static </em><code class="descname">vertex_to_voxel_linear_interpolation</code><span class="sig-paren">(</span><em>lh_vertex_to_voxel_linear_interpolation</em>, <em>rh_vertex_to_voxel_linear_interpolation</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.vertex_to_voxel_linear_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_linear_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.gray_indices. The vertex-values should be concatenated, LH
values then RH values.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.vertex_to_voxel_lines_interpolation">
<em class="property">static </em><code class="descname">vertex_to_voxel_lines_interpolation</code><span class="sig-paren">(</span><em>lh_vertex_to_voxel_lines_interpolation</em>, <em>rh_vertex_to_voxel_lines_interpolation</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.vertex_to_voxel_lines_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_lines_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.gray_indices. The vertex-values should be concatenated, LH
values then RH values.</dd>
</dl>
<p>The method works by projecting the vectors from the white surface vertices to the pial
surface vertices into the the ribbon and weighting them by the fraction of the vector that
lies in the voxel.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.vertex_to_voxel_matrix">
<em class="property">static </em><code class="descname">vertex_to_voxel_matrix</code><span class="sig-paren">(</span><em>voxel_to_vertex_matrix</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.vertex_to_voxel_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.vertex_to_voxel_matrix is the inverse matrix of sub.voxel_to_vertex_matrix.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.vertex_to_voxel_nearest_interpolation">
<em class="property">static </em><code class="descname">vertex_to_voxel_nearest_interpolation</code><span class="sig-paren">(</span><em>lh_vertex_to_voxel_nearest_interpolation</em>, <em>rh_vertex_to_voxel_nearest_interpolation</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.vertex_to_voxel_nearest_interpolation" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>sub.rh_gray_vertex_to_voxel_nearest_interpolation is a scipy sparse matrix representing the</dt>
<dd>interpolation from the vertices into the voxels; the ordering of the voxels that is
produced by the dot-product of this matrix with the vector of vertex-values is the same
as the ordering used in sub.lh_gray_indices.</dd>
</dl>
<p>The method used is nearest-neighbors to either the closest pial or white surface vertex.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.voxel_to_native_matrix">
<em class="property">static </em><code class="descname">voxel_to_native_matrix</code><span class="sig-paren">(</span><em>mtx</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.voxel_to_native_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.voxel_to_vertex_matrix is the 4x4 affine transformation matrix that converts from a
subject’s (0-indexed) voxel indices to that subject’s ‘native’ orientation; this is the
orientation matrix used when exporting a subject’s images, and should be the orientation
encoded in the subject’s image data.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.voxel_to_vertex_matrix">
<em class="property">static </em><code class="descname">voxel_to_vertex_matrix</code><span class="sig-paren">(</span><em>mtx</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.voxel_to_vertex_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.voxel_to_vertex_matrix is the 4x4 affine transformation matrix that converts from
(i,j,k) indices in the subject’s image/voxel space to (x,y,z) coordinates in the subject’s
cortical surface space.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="neuropythy.Subject.white_indices">
<em class="property">static </em><code class="descname">white_indices</code><span class="sig-paren">(</span><em>lh_white_indices</em>, <em>rh_white_indices</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.Subject.white_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>sub.white_indices is a frozenset of the indices of the white voxels in the given subject
represented as 3-tuples.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="neuropythy.retinotopy_data">
<code class="descclassname">neuropythy.</code><code class="descname">retinotopy_data</code><span class="sig-paren">(</span><em>m</em>, <em>source='any'</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.retinotopy_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>retinotopy_data(m) yields a dict containing a retinotopy dataset with the keys ‘polar_angle’,</dt>
<dd>‘eccentricity’, and any other related fields for the given retinotopy type; for example,
‘pRF_size’ and ‘variance_explained’ may be included for measured retinotopy datasets and
‘visual_area’ may be included for atlas or model datasets. The coordinates are always in the
‘visual’ retinotopy style, but can be reinterpreted with as_retinotopy.</dd>
<dt>retinotopy_data(m, source) may be used to specify a particular source for the data; this may be</dt>
<dd>either ‘empirical’, ‘model’, or ‘any’; or it may be a prefix/suffix beginning/ending with
an _ character.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="neuropythy.empirical_retinotopy_data">
<code class="descclassname">neuropythy.</code><code class="descname">empirical_retinotopy_data</code><span class="sig-paren">(</span><em>hemi</em>, <em>retino_type</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.empirical_retinotopy_data" title="Permalink to this definition">¶</a></dt>
<dd><p>empirical_retinotopy_data(hemi, t) yields a numpy array of data for the given cortex object hemi
and retinotopy type t; it does this by looking at the properties in hemi and picking out any
combination that is commonly used to denote empirical retinotopy data. These common names are
stored in _empirical_retintopy_names, in order of preference, which may be modified.
The argument t should be one of ‘polar_angle’, ‘eccentricity’, ‘weight’.</p>
</dd></dl>

<dl class="function">
<dt id="neuropythy.predicted_retinotopy_data">
<code class="descclassname">neuropythy.</code><code class="descname">predicted_retinotopy_data</code><span class="sig-paren">(</span><em>hemi</em>, <em>retino_type</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.predicted_retinotopy_data" title="Permalink to this definition">¶</a></dt>
<dd><p>predicted_retinotopy_data(hemi, t) yields a numpy array of data for the given cortex object hemi
and retinotopy type t; it does this by looking at the properties in hemi and picking out any
combination that is commonly used to denote empirical retinotopy data. These common names are
stored in _predicted_retintopy_names, in order of preference, which may be modified.
The argument t should be one of ‘polar_angle’, ‘eccentricity’, ‘visual_area’.</p>
</dd></dl>

<dl class="function">
<dt id="neuropythy.register_retinotopy">
<code class="descclassname">neuropythy.</code><code class="descname">register_retinotopy</code><span class="sig-paren">(</span><em>hemi</em>, <em>model='benson17'</em>, <em>model_hemi=Ellipsis</em>, <em>polar_angle=None</em>, <em>eccentricity=None</em>, <em>weight=None</em>, <em>pRF_radius=None</em>, <em>weight_min=0.1</em>, <em>eccentricity_range=None</em>, <em>partial_voluming_correction=False</em>, <em>radius_weight=1</em>, <em>field_sign_weight=1</em>, <em>scale=1.0</em>, <em>sigma=Ellipsis</em>, <em>select='close'</em>, <em>prior=None</em>, <em>resample=Ellipsis</em>, <em>radius=1.0471975511965976</em>, <em>max_steps=2000</em>, <em>max_step_size=0.05</em>, <em>method='random'</em>, <em>yield_imap=False</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.register_retinotopy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>register_retinotopy(hemi) registers the given hemisphere object, hemi, to a model of V1, V2,</dt>
<dd>and V3 retinotopy, and yields a copy of hemi that is identical but additionally contains
the registration ‘retinotopy’, whose coordinates are aligned with the model.</dd>
</dl>
<p>Registration attempts to align the vertex positions of the hemisphere’s spherical surface with a
model of polar angle and eccentricity. This alignment proceeds through several steps and can
be modified by several options. A description of these steps and options are provided here. For
most cases, the default options should work relatively well.</p>
<dl class="docutils">
<dt>Method:</dt>
<dd><ol class="first last arabic">
<li><dl class="first docutils">
<dt>Prepare for registration by several intitialization substeps:</dt>
<dd><ol class="first last loweralpha simple">
<li>Extract the polar angle, eccentricity and weight data from the hemisphere. These
data are usually properties on the mesh and can be modifies by the options
polar_angle, eccentricity, and weight, which can be either property names or list
of property values. By default (None), a property is chosen using the functions
neuropythy.vision.extract_retinotopy_argument with the default option set to
‘empirical’.</li>
<li>If partial voluming correction is enabled (via the option
partial_voluming_correction), multiply the weight by (1 - p) where p is 
hemi.partial_volume_factor.</li>
<li>If there is a prior that is specified as a belief about the retinotopy, then a
Registration is created for the hemisphere such that its vertices are arranged
according to that prior (see also the prior option). Note that because hemi’s
coordinates must always be projected into the registration specified by the model,
the prior must be the name of a registration to which the model’s specified subject
is also registered. This is clear in the case of an example. The default value for
this is ‘retinotopy’; assuming that our model is specified on the fsaverage_sym, 
surface, the initial positions of the coordinates for the registration process would
be the result of starting with hemi’s fsaverage_sym-aligned coordinates then warping
these coordinates in a way that is equivalent to the warping from fsaverage_sym’s 
native spherical coordinates to fsaverage_sym’s retinotopy registration coordinates.
Note that the retinotopy registration would usually be specified in a file in the
fsaverage_sym subject’s surf directory: surf/lh.retinotopy.sphere.reg.
If no prior is specified (option value None), then the vertices that are used are
those aligned with the registration of the model, which will usually be ‘fsaverage’
or ‘fsaverage_sym’.</li>
<li>If the option resample is not None, then the vertex coordinates are resampled onto
either the fsaverage or fsaverage_sym’s native sphere surface. (The value of resample
should be either ‘fsaverage’ or ‘fsaverage_sym’.) Resampling can prevent vertices
that have been rearranged by alignment with the model’s specified registration or by
application of a prior from beginning the alignment with very high initial gradients
and is recommended for subject alignments.
If resample is None then no changes are made.</li>
<li>A 2D projection of the (possibly aligned, prior-warped, and resampled) cortical
surface is made according to the projection parameters of the model. This map is the
mesh that is warped to eventually fit the model.</li>
</ol>
</dd>
</dl>
</li>
<li><p class="first">Perform the registration by running neuropythy.registration.mesh_register. This step
consists of two major components.</p>
<blockquote>
<div><ol class="loweralpha">
<li><p class="first">Create the potential function, which we will minimize. The potential function is a
complex function whose inputs are the coordinates of all of the vertices and whose
output is a potential value that increases both as the mesh is warped and as the
vertices with retinotopy predictions get farther away from the positions in the model
that their retinotopy values would predict they should lie. The balance of these
two forces is best controlled by the option functional_scale. The potential function
fundamentally consists of four terms; the first three describe mesh deformations and
the last describes the model fit.</p>
<blockquote>
<div><ul class="simple">
<li>The edge deformation term is described for any vertices u and v that are connected
by an edge in the mesh; it’s value is c/p (r(u,v) - r0(u,v))^2 where c is the
edge_scale, p is the number of edges in the mesh, r(a,b) is the distance between
vertices a and b, and r0(a,b) is the distance between a and b in the initial mesh.</li>
<li>The angle deformation term is described for any three vertices (u,v,w) that form
an angle in the mesh; its value is c/m h(t(u,v,w), t0(u,v,w)) where c is the
angle_scale argument, m is the number of angles in the mesh, t is the value of the
angle (u,v,w), t0 is the value of the angle in the initial mesh, and h(t,t0) is an
infinite-well function that asymptotes to positive infinity as t approaches both 0
and pi and is minimal when t = t0 (see the nben’s 
nben.mesh.registration.InfiniteWell documentation for more details).</li>
<li>The perimeter term prevents the perimeter vertices form moving significantly;
this primarily prevents the mesh from wrapping in on itself during registration.
The form of this term is, for any vertex u on the mesh perimeter, 
(x(u) - x0(u))^2 where x and x0 are the position and initial position of the
vertex.</li>
<li>Finally, the functional term is minimized when the vertices best align with the
retinotopy model.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Register the mesh vertices to the potential function using the nben Java library. The
particular parameters of the registration are method, max_steps, and max_step_size.</p>
</li>
</ol>
</div></blockquote>
</li>
</ol>
</dd>
<dt>Options:</dt>
<dd><ul class="first last simple">
<li>model specifies the instance of the retinotopy model to use; this must be an
instance of the RegisteredRetinotopyModel class or a string that can be passed to the
retinotopy_model() function (default: ‘standard’).</li>
<li>model_hemi specifies the hemisphere of the model; generally you shouldn’t have to set this
unless you are using an fsaverage_sym model, in which case it should be set to None; in all
other cases, the default value (Ellipsis) instructs the function to auto-detect the
hemisphere.</li>
<li>polar_angle, eccentricity, pRF_radius, and weight specify the property names for the
respective quantities; these may alternately be lists or numpy arrays of values. If weight
is not given or found, then unity weight for all vertices is assumed. By default, each will
check the  hemisphere’s properties for properties with compatible names; it will prefer the
properties PRF_polar_angle, PRF_ecentricity, and PRF_variance_explained if possible.</li>
<li>weight_min (default: 0.1) specifies the minimum value a vertex must have in the weight
property in order to be considered as retinotopically relevant.</li>
<li>eccentricity_range (default: None) specifies that any vertex whose eccentricity is too low
or too high should be given a weight of 0 in the registration.</li>
<li>partial_voluming_correction (default: True), if True, specifies that the value
(1 - hemi.partial_volume_factor) should be applied to all weight values (i.e., weights
should be down-weighted when likely to be affected by a partial voluming error).</li>
<li>field_sign_weight (default: 1) indicates the relative weight (between 0 and 1) that should
be given to the field-sign as a method of determining which anchors have the strongest
springs. A value of 1 indicates that the effective weights of anchors should be the 
geometric mean of the empirical retinotopic weight and field-sign-based weight; a value of 0
indicates that no attention should be paid to the field sign weight.</li>
<li>radius_weight (default: 1) indicates the relative weight (between 0 and 1) that should
be given to the pRF radius as a method of determining which anchors have the strongest
springs. A value of 1 indicates that the effective weights of anchors should be the 
geometric mean of the empirical retinotopic weight and pRF-radius-based weight; a value of 0
indicates that no attention should be paid to the radius-based weight.</li>
<li>sigma specifies the standard deviation of the Gaussian shape for the Schira model anchors;
see retinotopy_anchors for more information.</li>
<li>scale (default: 1.0) specifies the strength of the functional constraints (i.e. the anchors:
the part of the minimization responsible for ensuring that retinotopic coordinates are
aligned); the anatomical constraints (i.e. the edges and angles: the part of the
minimization responsible for ensuring that the mesh is not overly deformed) are always held
at a strength of 1.0.</li>
<li>select specifies the select option that should be passed to retinotopy_anchors.</li>
<li>max_steps (default 8,000) specifies the maximum number of registration steps to run.</li>
<li>max_step_size (default 0.05) specifies the maxmim distance a single vertex is allowed to
move in a single step of the minimization.</li>
<li>method (default ‘random’) is the method argument passed to mesh_register. This should be
‘random’, ‘pure’, or ‘nimble’. Generally, ‘random’ is recommended.</li>
<li>yield_imap (default: False) specifies whether the return value should be the new
Mesh object or a pimms imap (i.e., a persistent mapping of the result of a pimms
calculation) containing the meta-data that was used during the registration
calculations. If this is True, then register_retinotopy will return immediately, and
calculations will only be performed as the relevant data are requested from the returned
imap. The item ‘predicted_mesh’ gives the return value when yield_imap is set to False.</li>
<li>radius (default: pi/3) specifies the radius, in radians, of the included portion of the map
projection (projected about the occipital pole).</li>
<li>sigma (default Ellipsis) specifies the sigma argument to be passed onto the 
retinotopy_anchors function (see help(retinotopy_anchors)); the default value, Ellipsis,
is interpreted as the default value of the retinotopy_anchors function’s sigma option.</li>
<li>prior (default: None) specifies the prior that should be used, if found, in the 
topology registrations for the subject associated with the retinotopy_model’s registration.</li>
<li>resample (default: Ellipsis) specifies that the data should be resampled to one of
the uniform meshes, ‘fsaverage’ or ‘fsaverage_sym’, prior to registration; if None then no
resampling is performed; if Ellipsis, then auto-detect either fsaverage or fsaverage_sym
based on the model_hemi option (if it is None, fsaverage_sym, else fsaverage).</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="neuropythy.retinotopy_anchors">
<code class="descclassname">neuropythy.</code><code class="descname">retinotopy_anchors</code><span class="sig-paren">(</span><em>mesh, mdl, polar_angle=None, eccentricity=None, weight=None, weight_min=0.1, field_sign_weight=0, field_sign=None, radius_weight=0, radius_weight_source='Wandell2015', radius=None, model_field_sign=None, model_hemi=Ellipsis, scale=1, shape='Gaussian', suffix=None, sigma=[0.1, 2.0, 8.0], select='close'</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.retinotopy_anchors" title="Permalink to this definition">¶</a></dt>
<dd><p>retinotopy_anchors(mesh, model) is intended for use with the mesh_register function and the
retinotopy_model() function and/or the RetinotopyModel class; it yields a description of the
anchor points that tie relevant vertices the given mesh to points predicted by the given model
object. Any instance of the RetinotopyModel class should work as a model argument; this includes
SchiraModel objects as well as RetinotopyMeshModel objects such as those returned by the
retinotopy_model() function. If the model given is a string, then it is passed to the
retinotopy_model() function first.</p>
<dl class="docutils">
<dt>Options:</dt>
<dd><ul class="first last simple">
<li>polar_angle (default None) specifies that the given data should be used in place of the
‘polar_angle’ or ‘PRF_polar_angle’  property values. The given argument must be numeric and
the same length as the the number of vertices in the mesh. If None is given, then the
property value of the mesh is used; if a list is given and any element is None, then the
weight for that vertex is treated as a zero. If the option is a string, then the property
value with the same name isused as the polar_angle data.</li>
<li>eccentricity (default None) specifies that the given data should be used in places of the
‘eccentricity’ or ‘PRF_eccentricity’ property values. The eccentricity option is handled 
virtually identically to the polar_angle option.</li>
<li>weight (default None) specifies that the weight or scale of the data; this is handled
generally like the polar_angle and eccentricity options, but may also be 1, indicating that
all vertices with polar_angle and eccentricity values defined will be given a weight of 1.
If weight is left as None, then the function will check for ‘weight’,
‘variance_explained’, ‘PRF_variance_explained’, and ‘retinotopy_weight’ values and will use
the first found (in that order). If none of these is found, then a value of 1 is assumed.</li>
<li>weight_min (default 0) specifies that the weight must be higher than the given value inn
order to be included in the fit; vertices with weights below this value have their weights
truncated to 0.</li>
<li>scale (default 1) specifies a constant by which to multiply all weights for all anchors; the
value None is interpreted as 1.</li>
<li>shape (default ‘Gaussian’) specifies the shape of the potential function (see mesh_register)</li>
<li>model_hemi (default: None) specifies the hemisphere of the model to load; if None, then
looks for a non-specific model.</li>
<li>suffix (default None) specifies any additional arguments that should be appended to the 
potential function description list that is produced by this function; i.e., the 
retinotopy_anchors function produces a list, and the contents of suffix, if given and not
None, are appended to that list (see mesh_register).</li>
<li>select (default ‘close’) specifies a function that will be called with two arguments for
every vertex given an anchor; the arguments are the vertex label and the matrix of anchors.
The function should return a list of anchors to use for the label (None is equivalent to
lambda id,anc: anc). The parameter may alternately be specified using the string ‘close’:
select=[‘close’, [k]] indicates that any anchor more than k times the average edge-length in
the mesh should be excluded; a value of just [‘close’, k] on the other hand indicates that
any anchor more than k distance from the vertex should be exlcuded. The default value,
‘close’, is equivalent to [‘close’, [40]].</li>
<li>sigma (default [0.1, 2.0, 4.0]) specifies how the sigma parameter should be handled; if
None, then no sigma value is specified; if a single number, then all sigma values are
assigned that value; if a list of three numbers, then the first is the minimum sigma value,
the second is the fraction of the minimum distance between paired anchor points, and the 
last is the maximum sigma — the idea with this form of the argument is that the ideal
sigma value in many cases is approximately 0.25 to 0.5 times the distance between anchors
to which a single vertex is attracted; for any anchor a to which a vertex u is attracted,
the sigma of a is the middle sigma-argument value times the minimum distance from a to all
other anchors to which u is attracted (clipped by the min and max sigma).</li>
<li>field_sign_weight (default: 0) specifies the amount of weight that should be put on the
retinotopic field of the model as a method of attenuating the weights on those anchors whose
empirical retinotopic values and predicted model locations do not match. The weight that
results is calculated from the difference in empirical field-sign for each vertex and the
visual area field sign based on the labels in the model. The higher the field-sign weight,
(approaching 1) the more the resulting value is a geometric mean of the field-sign-based
weight and the original weights. As this value approaches 0, the resulting weights are more
like the original weights.</li>
<li>radius_weight (default: 0) specifies the amount of weight that should be put on the
receptive field radius of the model as a method of attenuating the weights on those anchors
whose empirical retinotopic values and predicted model locations do not match. The weight
that results is calculated from the difference in empirical RF radius for each vertex and
the predicted RF radius based on the labels in the model. The higher the radius weight,
(approaching 1) the more the resulting value is a geometric mean of the field-sign-based
weight and the original weights. As this value approaches 0, the resulting weights are more
like the original weights.</li>
<li>radius_weight_source (default: ‘Wandell2015’) specifies the source for predicting RF radius;
based on eccentricity and visual area label.</li>
</ul>
</dd>
<dt>Example:</dt>
<dd><p class="first"># The retinotopy_anchors function is intended for use with mesh_register, as follows:
# Define our Schira Model:
model = neuropythy.registration.SchiraModel()
# Make sure our mesh has polar angle, eccentricity, and weight data:
mesh.prop(‘polar_angle’,  polar_angle_vertex_data);
mesh.prop(‘eccentricity’, eccentricity_vertex_data);
mesh.prop(‘weight’,       variance_explained_vertex_data);
# register the mesh using the retinotopy and model:
registered_mesh = neuropythy.registration.mesh_register(</p>
<blockquote class="last">
<div>mesh,
[‘mesh’, retinotopy_anchors(mesh, model)],
max_step_size=0.05,
max_steps=2000)</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="neuropythy.retinotopy_model">
<code class="descclassname">neuropythy.</code><code class="descname">retinotopy_model</code><span class="sig-paren">(</span><em>name='benson17'</em>, <em>hemi=None</em>, <em>radius=1.2566370614359172</em>, <em>sphere_radius=100.0</em>, <em>search_paths=None</em>, <em>update=False</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.retinotopy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>retinotopy_model() yields a standard retinotopy model of V1, V2, and V3 as well as other areas
(depending on the options). The model itself is represented as a RegisteredRetinotopyModel
object, which may internally store a set of meshes with values at the vertices that define the
polar angle and eccentricity, or as another object (such as with the SchiraModel). The mesh
models are loaded from files in the neuropythy lib directory. Because the model’s class is
RegisteredRetinotopyModel, so the details of the model’s 2D projection onto the cortical surface
are included in the model.</p>
<dl class="docutils">
<dt>The following options may be given:</dt>
<dd><ul class="first last simple">
<li>name (default: ‘benson17’) indicates the name of the model to load; the Benson17 model is
included with the neuropythy library along with various others. If name is a filename, this
file is loaded (must be a valid fmm or fmm.gz file). Currently, models that are included
with neuropythy are: Benson17, Benson17-uncorrected, Schira10, and Benson14 (which is
identical to Schira10, as Schira10 was used by Benson14).</li>
<li>hemi (default: None) specifies that the model should go with a particular hemisphere, either
‘lh’ or ‘rh’. Generally, model files are names lh.&lt;model&gt;.fmm.gz or rh.&lt;model&gt;.fmm.gz, but
models intended for the fsaverage_sym don’t necessarily get a prefix. Note that you can
leave this as none and just specify that the model name is ‘lh.model’ instead.</li>
<li>radius, sphere_radius (defaults: pi/2.5 and 100.0, respectively) specify the radius of the
projection (on the surface of the sphere) and the radius of the sphere (100 is the radius
for Freesurfer spheres). See neuropythy.registration.load_fmm_model for mode details.</li>
<li>search_paths (default: None) specifies directories in which to look for fmm model files. No
matter what is included in these files, the neuropythy library’s folders are searched last.</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="neuropythy.neighborhood_cortical_magnification">
<code class="descclassname">neuropythy.</code><code class="descname">neighborhood_cortical_magnification</code><span class="sig-paren">(</span><em>mesh</em>, <em>coordinates</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.neighborhood_cortical_magnification" title="Permalink to this definition">¶</a></dt>
<dd><p>neighborhood_cortical_magnification(mesh, visual_coordinates) yields a list of neighborhood-
based cortical magnification values for the vertices in the given mesh if their visual field
coordinates are given by the visual_coordinates matrix (must be like [x_values, y_values]). If
either x-value or y-value of a coordinate is either None or numpy.nan, then that cortical
magnification value is numpy.nan.</p>
</dd></dl>

<dl class="function">
<dt id="neuropythy.as_retinotopy">
<code class="descclassname">neuropythy.</code><code class="descname">as_retinotopy</code><span class="sig-paren">(</span><em>data</em>, <em>output_style='visual'</em>, <em>units=Ellipsis</em>, <em>prefix=None</em>, <em>suffix=None</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.as_retinotopy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>as_retinotopy(data) converts the given data, if possible, into a 2-tuple, (polar_angle, eccen),</dt>
<dd>both in degrees, with 0 degrees of polar angle corresponding to the upper vertical meridian
and negative values corresponding to the left visual hemifield.</dd>
<dt>as_retinotopy(data, output_style) yields the given retinotopy data in the given output_style;</dt>
<dd>as_retinotopy(data) is equivalent to as_retinotopy(data, ‘visual’).</dd>
</dl>
<p>This function is intended as a general conversion routine between various sources of retinotopy
data. All lookups are done in a case insensitive manner. Data may be specified in any of the
following ways:</p>
<blockquote>
<div><ul class="simple">
<li>A cortical mesh containing recognized properties (such as ‘polar_angle’ and ‘eccentricity’
or ‘latitude’ and ‘longitude’.</li>
<li>A dict with recognized fields.</li>
<li>A tuple of (polar_angle, eccentricity) (assumed to be in ‘visual’ style).</li>
<li>A numpy vector of complex numbers (assumed in ‘complex’ style).</li>
<li>An n x 2 or 2 x n matrix whose rows/columns are (polar_angle, eccentricity) values (assumed
in ‘visual’ style).</li>
</ul>
</div></blockquote>
<dl class="docutils">
<dt>The following output_styles are accepted:</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>‘visual’:       polar-axis:         upper vertical meridian</dt>
<dd>positive-direction: clockwise
fields:             [‘polar_angle’ (degrees), ‘eccentricity’ (degrees)]</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘spherical’:    polar-axis:         right horizontal meridian</dt>
<dd>positive-direction: counter-clockwise
fields:             [‘theta’ (radians), ‘rho’ (radians)]</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘standard’:     polar-axis:         right horizontal meridian</dt>
<dd>positive-direction: counter-clockwise
fields:             [‘angle’ (radians), ‘eccentricity’ (degrees)]</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘cartesian’:    axes:               x/y correspond to RHM/UVM</dt>
<dd>positive-direction: left/up
fields:             (‘x’ (radians), ‘y’ (radians))</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘geographical’: axes:               x/y correspond to RHM/UVM</dt>
<dd>positive-direction: left/up
fields:             (‘longitude’ (degrees), ‘latitude’ (degrees))</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘complex’:      axes:               x/y correspond to RHM/UVM</dt>
<dd>positive-direction: left/up
fields:             longitude (degrees) + I*latitude (degrees)</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘complex-rad’:  axes:               x/y correspond to RHM/UVM</dt>
<dd>positive-direction: left/up
fields:             longitude (radians) + I*latitude (radians)</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘visual-rad’:   polar-axis:         upper vertical meridian</dt>
<dd>positive-direction: clockwise
fields:             [‘angle’ (radians), ‘eccentricity’ (radians)]</dd>
</dl>
</li>
</ul>
</dd>
<dt>The following options may be given:</dt>
<dd><ul class="first last simple">
<li>units (Ellipsis) specifies the unit that should be assumed (degrees or radians);
if Ellipsis is given, then auto-detect the unit if possible. This may be a map whose keys
are ‘polar_angle’ and ‘eccentricity’ (or the equivalent titles in data) and whose keys are
the individual units.</li>
<li>prefix (None) specifies a prefix that is required for any keys or property names.</li>
<li>suffix (None) specifies a suffix that is required for any keys or property names.</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="neuropythy.freesurfer_subject">
<code class="descclassname">neuropythy.</code><code class="descname">freesurfer_subject</code><span class="sig-paren">(</span><em>name</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.freesurfer_subject" title="Permalink to this definition">¶</a></dt>
<dd><p>subject(name) yields a freesurfer Subject object for the subject with the given name.
Subjects are cached and not reloaded.
Note that subects returned by freesurfer_subject() are always persistent Immutable objects; this
means that you must create a transient version of the subject to modify it via the member
function sub.transient(). Better, you can make copies of the objects with desired modifications
using the copy method.</p>
</dd></dl>

<dl class="function">
<dt id="neuropythy.to_mgh">
<code class="descclassname">neuropythy.</code><code class="descname">to_mgh</code><span class="sig-paren">(</span><em>obj</em>, <em>like=None</em>, <em>header=None</em>, <em>affine=None</em>, <em>extra=Ellipsis</em><span class="sig-paren">)</span><a class="headerlink" href="#neuropythy.to_mgh" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>to_mgh(obj) yields an MGHmage object that is as equivalent as possible to the given object obj.</dt>
<dd>If obj is an MGHImage already and no changes are requested, then it is returned unmolested;
otherwise, the optional arguments can be used to edit the header, affine, and exta.</dd>
<dt>The following options are accepted:</dt>
<dd><ul class="first last simple">
<li>like (default: None) may be provided to give a guide for the various header- and meta-data
that is included in the image. If this is a nifti image object, its meta-data are used; if
this is a subject, then the meta-data are deduced from the subject’s voxel and native
orientation matrices. All other specific options below override anything deduced from the
like argument.</li>
<li>header (default: None) may be a Nifti1 or Niti2 image header to be used as the nifti header
or to replace the header in a new image.</li>
<li>affine (default: None) may specify the affine transform to be given to the image object.</li>
<li>extra (default: Ellipsis) may specify an extra mapping for storage with the image data; the
default value Ellipsis indicates that such a mapping should be left as is if it already
exists in the obj or in the like option and should otherwise be empty.</li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
</ul>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Noah C. Benson.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.6</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>